{
  "out_dir": "gpt2_finetuned",
  "init_from": "resume",
  "eval_interval": 20,
  "eval_iters": 10,
  "log_interval": 2,
  "always_save_checkpoint": true,
  "override_checkpoint": true,
  "wandb_log": false,
  "wandb_project": "gpt2_finetuned",
  "wandb_run_name": "mini-gpt",
  "dataset": "prince",
  "gradient_accumulation_steps": 8,
  "batch_size": 4,
  "dropout": 0.2,
  "learning_rate": 3e-4,
  "max_iters": 5000,
  "lr_decay_iters": 5000,
  "min_lr": 3e-5,
  "beta2": 0.99,
  "warmup_iters": 100
}
