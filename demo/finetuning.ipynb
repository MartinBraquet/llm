{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.sample import Sampler\n",
    "from llm.train import Trainer\n",
    "\n",
    "config_file = 'train_gpt2_finetuned.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: init_from = gpt2-xl\n",
      "Overriding: out_dir = gpt2_finetuned\n",
      "Overriding: dataset = prince\n",
      "Overriding: eval_interval = 20\n",
      "Overriding: eval_iters = 10\n",
      "Overriding: log_interval = 2\n",
      "Overriding: always_save_checkpoint = True\n",
      "Overriding: gradient_accumulation_steps = 8\n",
      "Overriding: batch_size = 4\n",
      "Overriding: dropout = 0.2\n",
      "Overriding: learning_rate = 0.0003\n",
      "Overriding: max_iters = 20\n",
      "Overriding: lr_decay_iters = 20\n",
      "Overriding: min_lr = 3e-05\n",
      "Overriding: beta2 = 0.99\n",
      "Overriding: warmup_iters = 100\n",
      "Using device cuda\n",
      "tokens per iteration will be: 32,768\n",
      "Initializing from OpenAI GPT-2 weights: gpt2-xl\n",
      "loading weights from pretrained gpt: gpt2-xl\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "overriding dropout rate to 0.2\n",
      "1555.97M parameters (5935.57MB)\n",
      "num decayed parameter tensors: 194, with 1,556,609,600 parameters\n",
      "num non-decayed parameter tensors: 386, with 1,001,600 parameters\n",
      "using fused AdamW: True\n",
      "compiling the model...\n",
      "step 0: train loss 2.5921, val loss 2.6414\n",
      "step 1: train loss 2.6467, val loss 2.6500\n",
      "saving checkpoint to /workspace/llm/results/gpt2_finetuned/ckpt_init.pt\n",
      "iter 2: loss 2.2347, time 2084.90ms\n",
      "iter 4: loss 2.3769, time 2088.43ms\n",
      "iter 6: loss 2.1242, time 2094.23ms\n",
      "iter 8: loss 1.9942, time 2096.66ms\n",
      "iter 10: loss 1.9667, time 2096.98ms\n",
      "iter 12: loss 1.7085, time 2096.08ms\n",
      "iter 14: loss 1.5371, time 2102.30ms\n",
      "iter 16: loss 1.5587, time 2100.61ms\n",
      "iter 18: loss 1.1984, time 2106.64ms\n",
      "Training done, best_val_loss = 2.649963855743408\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config_file=config_file)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Using model in /workspace/llm/results/gpt2_finetuned/ckpt_init.pt\n",
      "1555.97M parameters (5935.57MB)\n",
      "Output:\n",
      "The essential is invisible to the common man, but that which is essential to us so is called in the proper name. And, therefore, the power or work of generation is an essential to the nature of an orderly creature, for it serves for the preservation of the natural order of the generation.\n",
      "\n",
      "Secondly, God by the very power which is ordained to man, produces a true and sensible image of himself, as has been observed. But the image is caused somewhat by the principle of resemblance; and therefore order is made\n"
     ]
    }
   ],
   "source": [
    "sampler = Sampler(out_dir=trainer.config.out_dir, checkpoint_name='ckpt_init.pt')\n",
    "print('Output:')\n",
    "print(sampler.generate_text(prompt='The essential is invisible to'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Using model in /workspace/llm/results/gpt2_finetuned/ckpt.pt\n",
      "1555.97M parameters (5935.57MB)\n",
      "Output:\n",
      "The essential is invisible to the eye; the indispensable is invisible to the mind. It is a matter that is very simple. To be useful, a thing requires not only the use of some special quality, but also the permission of some one to use it. If the tiger... ‎ Appears in 12 books from 1920-2003\n",
      "\n",
      "Page 114 - If you wish to make a true landscape, it is necessary to have at least some idea of the peaks and valleys. Otherwise the journey cannot be made easy... ‎ Appears in\n"
     ]
    }
   ],
   "source": [
    "sampler = Sampler(out_dir=trainer.config.out_dir)\n",
    "print('Output:')\n",
    "print(sampler.generate_text(prompt='The essential is invisible to'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You don’t live here,” said the little prince to himself, as he continued farther on his journey. “But perhaps I shall find a watering can \n",
      "in the grass, some morning. And then I shall know that somewhere among the stars my sheep is \n",
      "laying \n",
      "down her golden eyes.” \n",
      "\n",
      "“That may be,” replied the fox. “But you will not be happy until you reach the seed-plot\n"
     ]
    }
   ],
   "source": [
    "print(sampler.generate_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love is the answer to all question.  \n",
      "Q: \n",
      "And how does it come to be in the sky?  \n",
      "A: \n",
      "\n",
      "It is just like a seed. It is invisible, and yet it is very real. It grows... \n",
      "\n",
      "The only thing that is necessary is for a heart to be true. Once a seed has been planted... \n",
      "\n",
      "When the time comes for the flower to produce a flower, its invisible shoots will begin to appear... \n",
      "\n",
      "At night the wind blows the tiny shoots that are growing on the flower. It is from these that the little prince got the idea of putting his stars in the sand. You see, the earth is very small... \n",
      "\n",
      "He covered the planet with a blanket...  \n",
      "\n",
      "One night, after working so hard, the little prince went to sleep. And just like that, without waking up... he was dreaming! \n",
      "\n",
      "That is how he came to be where he was... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sampler.generate_text(prompt='Love is the answer', max_tokens=200))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
