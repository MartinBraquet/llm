{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.7305, val loss 4.7241\n",
      "step 300: train loss 2.8110, val loss 2.8249\n",
      "step 600: train loss 2.5434, val loss 2.5682\n",
      "step 900: train loss 2.4932, val loss 2.5088\n",
      "step 1200: train loss 2.4863, val loss 2.5035\n",
      "step 1500: train loss 2.4665, val loss 2.4921\n",
      "step 1800: train loss 2.4683, val loss 2.4936\n",
      "step 2100: train loss 2.4696, val loss 2.4846\n",
      "step 2400: train loss 2.4638, val loss 2.4879\n",
      "step 2700: train loss 2.4738, val loss 2.4911\n",
      "\n",
      "od nos CAy go ghanoray t, co haringoudrou clethe k,LARof fr werar,\n",
      "Is fa!\n",
      "\n",
      "\n",
      "Thilemel cia h hmboomyorarifrcitheviPO, tle dst f qur'dig t cof boddo y t o ar pileas h mo wierl t,\n",
      "S:\n",
      "STENENEat I athe thounomy tinrent distesisanimald 3I: eliento ald, avaviconofrisist me Busarend un'soto vat s k,\n",
      "SBRI he the f wendleindd t acoe ts ansu, thy ppr h.QULY:\n",
      "KIIsqu pr odEd ch,\n",
      "APrnes ouse bll owhored miner t ooon'stoume bupromo! fifoveghind hiarnge s.\n",
      "MI aswimy or m, wardd tw'To tee abifewoetsphin sed The a\n"
     ]
    }
   ],
   "source": [
    "! python bigram.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.553 k parameters\n",
      "step 0: train loss 4.2000, val loss 4.2047\n",
      "step 500: train loss 2.6911, val loss 2.7087\n",
      "step 1000: train loss 2.5196, val loss 2.5303\n",
      "step 1500: train loss 2.4775, val loss 2.4829\n",
      "step 2000: train loss 2.4408, val loss 2.4523\n",
      "step 2500: train loss 2.4272, val loss 2.4435\n",
      "step 3000: train loss 2.4130, val loss 2.4327\n",
      "step 3500: train loss 2.3956, val loss 2.4212\n",
      "step 4000: train loss 2.4041, val loss 2.3992\n",
      "step 4500: train loss 2.3980, val loss 2.4084\n",
      "step 4999: train loss 2.3951, val loss 2.4126\n",
      "\n",
      "Shiserrs eler fo itha thes I ha thorn hif wavoufa,\n",
      "'ETCHANG ies, indd rieen eedrouh o, ld whe for day.\n",
      "ORIAMourt fo hey th, hy ntoul om see.\n",
      "\n",
      "f ane he ce avof the\n",
      "YAeretoingo. Lit out?-\n",
      "PINENUTOCAIFIcoulthe, ger bleancoover ser'd thines sb, shalilais sety I tansu cul torat t-\n",
      "I'splae pioucchere, I as, out irged wron.\n",
      "\n",
      "Wher,\n",
      "NUVMI cirut lid bleant fad I the:\n",
      "Andsifokerad theckard then.\n",
      "'T mepers?\n",
      "Whte\n",
      "Mon. I wl yovean shoulld?\n",
      "\n",
      "Bure hevend;\n",
      "Srienanged ds If!\n",
      "Asut I ar seon: wo inout bllant\n",
      "re han\n"
     ]
    }
   ],
   "source": [
    "! python single_head.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python gpt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
